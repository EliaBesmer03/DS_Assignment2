# The Anatomy of a Search Engine

The repository contains a gradle applications project template for completing Assignment 2.

### Project Structure

```bash
src
└── main
│    ├── java
          ├── com.example.searchengine
│    │              ├── Crawler.java # Abstract class for all crawlers. This class needs to be completed for task 1.
                    └── IndexInverter.java #Implementation of a class with a method to create the inverted index from the index. This class needs to be completed for task 2.
│    │              └── MultithreadCrawler.java #Instantiation of a multithreaded crawler. This class needs to be completed for task 4.
│    │              └── SearchEngine.java #Implementation of a search engine. This class needs to be completed for task 3.
                    └── SearchEngineApplication.java #Main Spring class, this class does not need to be modified.
                    └── SearchEngineProperties.java #Spring class to define the properties, which are read from the application.properties file. This file does not need to be modified.
                    └── Searcher.java #Implementation of a class with a method to search the URLs corresponding to a keyword using the inverted index. This task needs to be completed for task 2.
│    │              └── SimpleCrawler.java #Instantiation of a simple crawler (with only one thread). This class needs to be completed for task 1.
│    ├──  resources
          ├── static
          │      └── index.html  # The main page of the search engine
│         └── index.csv  # CSV file to store the index generated by the crawler.
│         └── inverted_index.csv  # CSV file to store the inverted index generated by the index inverter.
│         └── search_engine_api.yaml  # OpenAPI specification of the Search Engine (TO COMPLETE)
└── test
      ├── TestBase.java # The base class for all tests. This class is not to be used independently.
      ├──CrawlerTest.java # The base class for all crawler tests. This class is not to be used independently.
      ├── SimpleCrawlerTest.java # The tests in this class needs to work to validate task 1.
      ├── MultithreadCrawlerTest.java # The tests in this class needs to work to validate task 4.
      ├── IndexInverterTest.java # The tests in this class needs to work to validate task 2.
      ├── SearcherTest.java # The tests in this class needs to work to validate task 2.
      └── SearchEngineTest.java #T he test in this class needs to work to validate task 3.

├──.gitignore # A file used by git to indicate the files that are not added to git.
├── build.gradle # A file used by Gradle to indicate how to build the project.
├── gradlew # A file used by Gradle on Linux/Mac computers.
├── gradlew.bat # A file used by Gradle on Windows computers.
├── README.md # This file, with the instructions.
├── Report.md # The Report, to complete and send back
└── settings.gradle # A file used by Gradle
```

## Task 1


In this task, you have to implement a crawler that generates a CSV file [`index.csv`](src/main/resources/index.csv) that represents
the hypermedia environment. The crawling operation should start from the Web page at URL: https://api.interactions.ics.unisg.ch/hypermedia-environment/cc2247b79ac48af0.
The CSV file is a table that contains, for each Web page, the contents (three terms) that occur on that Web page.
You should first complete the `getInfo` method of the [`Crawler`](src/main/java/com/example/searchengine/Crawler.java) class (that will be reused by the MultithreadCrawler in task 4). To do so, you can use the [`OKHttp`](https://square.github.io/okhttp/) HTTP client and the [`Jsoup`](https://jsoup.org/apidocs/) HTML parser.
and then the [`SimpleCrawler`](src/main/java/com/example/searchengine/SimpleCrawler.java) class. To process the CSV file, you should use the classes [`CSVReader`](https://opencsv.sourceforge.net/apidocs/com/opencsv/CSVReader.html) and [`CSVWriter`](https://opencsv.sourceforge.net/apidocs/com/opencsv/CSVWriter.html).

### Logging information

Your classes can contain a logger. You can use this logger to select the log level of the printed message. The message will only be printed if it is at least at the log level configured in [`log4j2.xml`](src/main/resources/log4j2.xml). The log levels are: TRACE, DEBUG, INFO, WARN, ERROR.

### Run the tests for the class SimpleCrawlerTest. You should have a successful build to pass the test.

> ⚠️ Tests are only indicative. If a test fails, your code is probably not correct but the test may pass while the code is not correct. This is true for all tests indicated in this README.

On Linux and macOS:

```bash
./gradlew test --tests "SimpleCrawlerTest"

```

On Windows:

```bash
.\gradlew test --tests "SimpleCrawlerTest"
```

Indicate the time necessary for the SimpleCrawler to work in Report.md.



## Task 2

In this task, you will implement another main component of your search engine, and experiment with it. For this, first, you have to complete the class [`IndexInverter`](src/main/java/com/example/searchengine/IndexInverter.java). This code should read the CSV file
[`index.csv`](src/main/resources/index.csv) from the crawler and invert the index. The inverted index should be in a file [`inverted_index.csv`](src/main/resources/inverted_index.csv).

Then, you should complete the `search` method of the [`Searcher`](src/main/java/com/example/searchengine/Searcher.java) class to be able to retrieve all URLs containing a keyword in the [`inverted_index.csv`](src/main/resources/inverted_index.csv) file.

### Run the tests for the class IndexInverterTest, and then SearcherTest. You should have a sucessful build to pass the test.

These tests should be performed only after the [`index.csv`](src/main/resources/index.csv) file has been created. You should perform the tests for the IndexInverter before performing the tests for the Searcher in order to have the inverted_index.csv file properly initialized. Otherwise, the tests may fail even if the code is correct.

On Linux and macOS:

```bash
./gradlew test --tests "IndexInverterTest"
./gradlew test --tests "SearcherTest"
```




On Windows:

```bash
.\gradlew test --tests "IndexInverterTest"
.\gradlew test --tests "SearcherTest"
```




## Task 3

The search engine is available as a Web service, which you will implement as part of this task. In
order to do so, you have to complete the program SearchEngine.java. This task has two parts.
In the first part, you will implement an HTTP API for your search engine based on a provided
OpenAPI specification. 
In the second part, you will extend, but not implement, the provided OpenAPI specification with an
administrator interface.

### Search Engine API

We provide you with an OpenAPI specification [`search_engine_api.yaml`](src/main/resources/search_engine_api.yaml)
for your search engine’s API in the assignment package. Your task is to complete the [`SearchEngine`](src/main/java/com/example/searchengine/SearchEngine.java) class to create a server that implements the API.
The search engine API supports two operations: a “search” operation that allows users to get
the URLs of the pages containing a certain keyword in a JSON array, and a “lucky” operation
performs a redirection to a Web page in the environment containing the keyword if one exists.

The file [`application.properties`](src/main/resources/application.properties) has been configured but you can update the proposed configuration:

- `server.port` defines the port. The port defined is 8080. You do not need to change it.
- `crawler` indicates the crawler to be used ("simple" for the SimpleCrawler. You can also use "multithread" for the MultithreadCrawler, once it has been implemented in Task 4).
- `crawl` is a boolean ("true" or "false") indicating whether the search engine should crawl the environment when the application is starting. 
If the file [`index.csv`](src/main/resources/index.csv) and [`inverted_index.csv`](src/main/resources/inverted_index.csv) are empty, then you should set crawl=true. Else, you can set crawl=false and the search engine will use the existing inverted_index.csv file.

Then, you can run the search engine.

On Linux and macOS:

```bash
./gradlew bootRun

```


On Windows:

```bash
.\gradlew bootRun

```

### Run the tests for the class SearchEngine. You should have a sucessful build to pass the test.

On Linux and macOS:

```bash
./gradlew test --tests "SearchEngineTest"

```


On Windows:

```bash
.\gradlew test --tests "SearchEngineTest"
```

When the search engine is running, go to the URL: "http://localhost:8080/" (or update the port if needed). You can try using the Search Engine interface there.




### Extending the API specification

Your task is to extend the OpenAPI specification in the file [`search_engine_api.yaml`](src/main/resources/search_engine_api.yaml), by writing the administration interface. The administration interface should enable administrators to launch a new crawling operation, to regenerate the inverted index, to delete a URL from the index, and update (or add) the keywords associated with a given URL
in the index, to indicate the status of the crawler (whether the crawler is running) and the status of the inverted index (whether the inverted index needs to be regenerated after a crawl operation, or an update in the index). You are also required to document all your design decisions as part of this task in Report.md. However, you are not required to implement these features in your search engine. Your design decisions should respect the semantics of the HTTP methods and status codes. You can use the [`Pet Store OpenAPI Specification`](https://petstore.swagger.io/#/) as inspiration.





## Task 4

Since the crawler spends a lot of time waiting for responses from the Web server in general,  multi-threading would lead to a large performance increase for your crawler.

Complete the code of the class [`MultithreadCrawler`](src/main/java/com/example/searchengine/MultithreadCrawler.java) to implement a multithread crawler. You can do so by completing the `crawl` method and the `CrawlerRunnable` inner class. `CrawlerRunnable` is a [`runnable`](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Runnable.html) to process each URL. Runnables are run within [`threads`](https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Thread.html). In Spring, you can use the [`ThreadPoolTaskExecutor`](https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/scheduling/concurrent/ThreadPoolTaskExecutor.html) to process threads.



### Run the tests for the class MultithreadCrawlerTest. You should have a successful build to pass the test.

On Linux and macOS:

```bash
./gradlew test --tests "MultithreadCrawlerTest"

```


On Windows:

```bash
.\gradlew test --tests "MultithreadCrawlerTest"
```

Indicate  the time necessary for the MultithreadedCrawler to work, and indicate the ratio of SimpleCrawler time / MultithreadedCrawler time in Report.md.

